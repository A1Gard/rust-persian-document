# تبدیل سرور تک‌ریسمانی ما به یک سرور چندریسمانی

در حال حاضر، سرور هر درخواست را به نوبت پردازش می‌کند، به این معنا که تا زمانی که پردازش درخواست اول تمام نشود، اتصال دوم را پردازش نخواهد کرد. اگر سرور درخواست‌های بیشتری دریافت کند، این اجرای سریالی کمتر و کمتر بهینه خواهد بود. اگر سرور درخواستی دریافت کند که پردازش آن زمان زیادی طول بکشد، درخواست‌های بعدی باید منتظر بمانند تا درخواست طولانی تمام شود، حتی اگر درخواست‌های جدید بتوانند به‌سرعت پردازش شوند. ما باید این مشکل را برطرف کنیم، اما ابتدا بیایید مشکل را در عمل ببینیم.

## شبیه‌سازی یک درخواست کند در پیاده‌سازی فعلی سرور

ما بررسی خواهیم کرد که چگونه یک درخواست با پردازش کند می‌تواند روی درخواست‌های دیگر به پیاده‌سازی فعلی سرور ما تأثیر بگذارد. Listing 21-10 پیاده‌سازی مدیریت یک درخواست به `/sleep` را با یک پاسخ کند شبیه‌سازی‌شده نشان می‌دهد که باعث می‌شود سرور به مدت پنج ثانیه قبل از پاسخ‌دادن بخوابد.

**فایل: src/main.rs**

```rust
use std::{
    fs,
    io::{BufReader, prelude::*},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};
// --snip--

fn handle_connection(mut stream: TcpStream) {
    // --snip--

    let (status_line, filename) = match &request_line[..] {
        "GET / HTTP/1.1" => ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" => {
            thread::sleep(Duration::from_secs(5));
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ => ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    // --snip--
}
```

**Listing 21-10: شبیه‌سازی یک درخواست کند با خوابیدن به مدت 5 ثانیه**

ما از `if` به `match` تغییر کردیم حالا که سه مورد داریم. باید به‌صراحت روی یک برش از `request_line` تطبیق الگو انجام دهیم تا با مقادیر لفظی رشته‌ای تطبیق پیدا کند؛ `match` ارجاع و رفع ارجاع خودکار را مانند متد برابری انجام نمی‌دهد.

بازوی اول همان بلوک `if` از Listing 21-9 است. بازوی دوم با یک درخواست به `/sleep` تطبیق می‌یابد. وقتی آن درخواست دریافت شود، سرور به مدت پنج ثانیه می‌خوابد قبل از رندر کردن صفحه HTML موفق. بازوی سوم همان بلوک `else` از Listing 21-9 است.

می‌توانید ببینید که سرور ما چقدر ابتدایی است: کتابخانه‌های واقعی تشخیص چندین درخواست را به روشی بسیار کم‌حجم‌تر مدیریت می‌کنند!

سرور را با استفاده از `cargo run` شروع کنید. سپس دو پنجره مرورگر باز کنید: یکی برای `http://127.0.0.1:7878/` و دیگری برای `http://127.0.0.1:7878/sleep`. اگر چند بار URI `/` را وارد کنید، مانند قبل، خواهید دید که به‌سرعت پاسخ می‌دهد. اما اگر `/sleep` را وارد کنید و سپس `/` را بارگذاری کنید، خواهید دید که `/` تا زمانی که `sleep` به مدت کامل پنج ثانیه خود نخوابیده منتظر می‌ماند تا بارگذاری شود.

تکنیک‌های متعددی وجود دارند که می‌توانیم برای جلوگیری از انباشته شدن درخواست‌ها پشت یک درخواست کند استفاده کنیم، از جمله استفاده از `async` همان‌طور که در فصل هفدهم انجام دادیم؛ تکنیکی که ما پیاده‌سازی خواهیم کرد یک استخر ریسمانی است.

## بهبود توان عملیاتی با یک استخر ریسمانی

یک **استخر ریسمانی** گروهی از ریسمان‌های ایجادشده است که منتظر و آماده برای مدیریت یک وظیفه هستند. وقتی برنامه یک وظیفه جدید دریافت می‌کند، یکی از ریسمان‌های موجود در استخر را به وظیفه اختصاص می‌دهد، و آن ریسمان وظیفه را پردازش خواهد کرد. ریسمان‌های باقی‌مانده در استخر برای مدیریت هر وظیفه دیگری که در حین پردازش ریسمان اول وارد می‌شود در دسترس هستند. وقتی ریسمان اول پردازش وظیفه خود را به پایان برساند، به استخر ریسمان‌های بیکار بازمی‌گردد، آماده برای مدیریت یک وظیفه جدید. یک استخر ریسمانی به شما امکان می‌دهد اتصالات را به‌صورت همزمان پردازش کنید، که توان عملیاتی سرور شما را افزایش می‌دهد.

ما تعداد ریسمان‌ها در استخر را به یک تعداد کوچک محدود خواهیم کرد تا از حملات منع سرویس (DoS) محافظت کنیم؛ اگر برنامه ما برای هر درخواست ورودی یک ریسمان جدید ایجاد کند، کسی که 10 میلیون درخواست به سرور ما بفرستد می‌تواند با استفاده از تمام منابع سرور و متوقف کردن پردازش درخواست‌ها، هرج‌ومرج ایجاد کند.

به‌جای ایجاد ریسمان‌های نامحدود، ما تعداد ثابتی از ریسمان‌ها را خواهیم داشت که در استخر منتظر هستند. درخواست‌هایی که وارد می‌شوند به استخر برای پردازش ارسال می‌شوند. استخر یک صف از درخواست‌های ورودی را نگه می‌دارد. هر یک از ریسمان‌های موجود در استخر یک درخواست را از این صف بیرون می‌کشد، درخواست را مدیریت می‌کند، و سپس از صف درخواست دیگری می‌خواهد. با این طراحی، ما می‌توانیم تا N درخواست را به‌صورت همزمان پردازش کنیم، که N تعداد ریسمان‌هاست. اگر هر ریسمان در حال پاسخ به یک درخواست طولانی‌مدت باشد، درخواست‌های بعدی همچنان می‌توانند در صف انباشته شوند، اما ما تعداد درخواست‌های طولانی‌مدتی که می‌توانیم قبل از رسیدن به آن نقطه مدیریت کنیم را افزایش داده‌ایم.

این تکنیک تنها یکی از راه‌های متعدد برای بهبود توان عملیاتی یک وب سرور است. گزینه‌های دیگر که ممکن است بخواهید کاوش کنید شامل مدل fork/join، مدل ورودی/خروجی ناهمزمان تک‌ریسمانی، و مدل ورودی/خروجی ناهمزمان چندریسمانی هستند. اگر به این موضوع علاقه‌مند هستید، می‌توانید درباره راه‌حل‌های دیگر بیشتر بخوانید و سعی کنید آن‌ها را پیاده‌سازی کنید؛ با یک زبان سطح پایین مانند Rust، همه این گزینه‌ها ممکن هستند.

قبل از اینکه شروع به پیاده‌سازی یک استخر ریسمانی کنیم، بیایید درباره اینکه استفاده از استخر باید چگونه باشد صحبت کنیم. وقتی سعی می‌کنید کد را طراحی کنید، نوشتن ابتدا رابط کلاینت می‌تواند به هدایت طراحی شما کمک کند. API کد را طوری بنویسید که به روشی که می‌خواهید آن را فراخوانی کنید ساختاربندی شده باشد؛ سپس عملکرد را در آن ساختار پیاده‌سازی کنید به‌جای اینکه ابتدا عملکرد را پیاده‌سازی کنید و سپس API عمومی را طراحی کنید.

مشابه اینکه چگونه در پروژه فصل دوازدهم از توسعه آزمون‌محور استفاده کردیم، اینجا از **توسعه هدایت‌شده توسط کامپایلر** استفاده خواهیم کرد. ما کدی را که توابع مورد نظرمان را فراخوانی می‌کند خواهیم نوشت، و سپس به خطاهای کامپایلر نگاه خواهیم کرد تا تعیین کنیم چه چیزی باید بعدی تغییر کند تا کد کار کند. با این حال، قبل از انجام این کار، تکنیکی را که قصد استفاده از آن را نداریم به‌عنوان نقطه شروع بررسی خواهیم کرد.

## ایجاد یک ریسمان برای هر درخواست

ابتدا، بیایید بررسی کنیم که کد ما اگر برای هر اتصال یک ریسمان جدید ایجاد کند چگونه به نظر می‌رسد. همان‌طور که قبلاً ذکر شد، این طرح نهایی ما نیست به دلیل مشکلات مربوط به ایجاد تعداد نامحدود ریسمان، اما یک نقطه شروع برای به دست آوردن ابتدا یک سرور چندریسمانی کارآمد است. سپس ما استخر ریسمانی را به‌عنوان یک بهبود اضافه خواهیم کنیم، و مقایسه دو راه‌حل آسان‌تر خواهد بود. Listing 21-11 تغییراتی را نشان می‌دهد که باید در `main` ایجاد کنیم تا یک ریسمان جدید برای مدیریت هر جریان در حلقه `for` ایجاد شود.

**فایل: src/main.rs**

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();

    for stream in listener.incoming() {
        let stream = stream.unwrap();

        thread::spawn(|| {
            handle_connection(stream);
        });
    }
}
```

**Listing 21-11: ایجاد یک ریسمان جدید برای هر جریان**

همان‌طور که در فصل شانزدهم آموختید، `thread::spawn` یک ریسمان جدید ایجاد خواهد کرد و سپس کد موجود در بسته‌بندی را در ریسمان جدید اجرا خواهد کرد. اگر این کد را اجرا کنید و `/sleep` را در مرورگر خود بارگذاری کنید، سپس `/` را در دو تب مرورگر دیگر بارگذاری کنید، خواهید دید که درخواست‌های به `/` نیازی به منتظر ماندن برای اتمام `/sleep` ندارند. با این حال، همان‌طور که ذکر کردیم، این در نهایت سیستم را تحت فشار قرار خواهد داد زیرا شما بدون هیچ محدودیتی ریسمان‌های جدید ایجاد می‌کنید.

همچنین ممکن است از فصل هفدهم به یاد بیاورید که این دقیقاً همان موقعیتی است که `async` و `await` واقعاً می‌درخشند! این را در نظر داشته باشید در حالی که استخر ریسمانی را می‌سازیم و فکر کنید که با `async` چه چیزهایی متفاوت یا یکسان خواهند بود.

## ایجاد تعداد محدودی از ریسمان‌ها

ما می‌خواهیم استخر ریسمانی ما به روشی مشابه و آشنا کار کند تا تغییر از ریسمان‌ها به یک استخر ریسمانی نیازی به تغییرات بزرگ در کدی که از API ما استفاده می‌کند نداشته باشد. Listing 21-12 رابط فرضی برای یک ساختار `ThreadPool` را نشان می‌دهد که می‌خواهیم به‌جای `thread::spawn` استفاده کنیم.

**فایل: src/main.rs**

<div class="err"> *<img src="img/does_not_compile.svg" > این کد کامپایل نمی‌شود!* </div>

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming() {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }
}
```

**Listing 21-12: رابط ایده‌آل ما برای ThreadPool**

ما از `ThreadPool::new` استفاده می‌کنیم تا یک استخر ریسمانی جدید با تعداد قابل تنظیم ریسمان‌ها، در این مورد چهار، ایجاد کنیم. سپس، در حلقه `for`، `pool.execute` رابطی مشابه `thread::spawn` دارد به این معنا که یک بسته‌بندی را می‌گیرد که استخر باید برای هر جریان اجرا کند. ما باید `pool.execute` را پیاده‌سازی کنیم تا بسته‌بندی را بگیرد و آن را به یک ریسمان در استخر برای اجرا بدهد. این کد هنوز کامپایل نخواهد شد، اما ما سعی خواهیم کرد تا کامپایلر ما را در چگونگی رفع آن راهنمایی کند.

## ساخت ThreadPool با استفاده از توسعه هدایت‌شده توسط کامپایلر

تغییرات موجود در Listing 21-12 را در `src/main.rs` اعمال کنید، و سپس بیایید از خطاهای کامپایلر از `cargo check` برای هدایت توسعه خود استفاده کنیم. این اولین خطایی است که دریافت می‌کنیم:

```
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0433]: failed to resolve: use of undeclared type `ThreadPool`
  --> src/main.rs:11:16
   |
11 |     let pool = ThreadPool::new(4);
   |                ^^^^^^^^^^ use of undeclared type `ThreadPool`

For more information about this error, try `rustc --explain E0433`.
error: could not compile `hello` (bin "hello") due to 1 previous error
```

عالی! این خطا به ما می‌گوید که به یک نوع یا ماژول `ThreadPool` نیاز داریم، بنابراین حالا یکی را خواهیم ساخت. پیاده‌سازی `ThreadPool` ما مستقل از نوع کاری که وب سرور ما انجام می‌دهد خواهد بود. بنابراین بیایید crate `hello` را از یک crate باینری به یک crate کتابخانه‌ای تغییر دهیم تا پیاده‌سازی `ThreadPool` ما را نگه دارد. پس از تغییر به یک crate کتابخانه‌ای، همچنین می‌توانیم از کتابخانه استخر ریسمانی جداگانه برای هر کاری که می‌خواهیم با استفاده از یک استخر ریسمانی انجام دهیم، نه فقط برای ارائه درخواست‌های وب، استفاده کنیم.

یک فایل `src/lib.rs` ایجاد کنید که شامل موارد زیر باشد، که ساده‌ترین تعریف یک ساختار `ThreadPool` است که می‌توانیم برای حالا داشته باشیم:

**فایل: src/lib.rs**

```rust
pub struct ThreadPool;
```

سپس فایل `main.rs` را ویرایش کنید تا `ThreadPool` را از crate کتابخانه‌ای به حوزه بیاورید با افزودن کد زیر به بالای `src/main.rs`:

**فایل: src/main.rs**

```rust
use hello::ThreadPool;
```

این کد هنوز کار نخواهد کرد، اما بیایید دوباره آن را بررسی کنیم تا خطای بعدی که باید برطرف کنیم را دریافت کنیم:

```
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0599]: no function or associated item named `new` found for struct `ThreadPool` in the current scope
  --> src/main.rs:12:28
   |
12 |     let pool = ThreadPool::new(4);
   |                            ^^^ function or associated item not found in `ThreadPool`

For more information about this error, try `rustc --explain E0599`.
error: could not compile `hello` (bin "hello") due to 1 previous error
```

این خطا نشان می‌دهد که بعدی باید یک تابع مرتبط به نام `new` برای `ThreadPool` ایجاد کنیم. همچنین می‌دانیم که `new` باید یک پارامتر داشته باشد که بتواند 4 را به‌عنوان آرگومان بپذیرد و باید یک نمونه `ThreadPool` را برگرداند. بیایید ساده‌ترین تابع `new` را پیاده‌سازی کنیم که این ویژگی‌ها را داشته باشد:

**فایل: src/lib.rs**

```rust
pub struct ThreadPool;

impl ThreadPool {
    pub fn new(size: usize) -> ThreadPool {
        ThreadPool
    }
}
```

ما نوع `usize` را برای پارامتر `size` انتخاب کردیم زیرا می‌دانیم که تعداد منفی ریسمان‌ها معنایی ندارد. همچنین می‌دانیم که این 4 را به‌عنوان تعداد عناصر در یک مجموعه از ریسمان‌ها استفاده خواهیم کرد، که نوع `usize` برای آن است، همان‌طور که در بخش «انواع صحیح» در فصل سوم بحث کردیم.

بیایید کد را دوباره بررسی کنیم:

```
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0599]: no method named `execute` found for struct `ThreadPool` in the current scope
  --> src/main.rs:17:14
   |
17 |         pool.execute(|| {
   |         -----^^^^^^^ method not found in `ThreadPool`

For more information about this error, try `rustc --explain E0599`.
error: could not compile `hello` (bin "hello") due to 1 previous error
```

حالا خطا رخ می‌دهد زیرا ما متد `execute` روی `ThreadPool` نداریم. به یاد بیاورید از بخش «ایجاد تعداد محدودی از ریسمان‌ها» که تصمیم گرفتیم استخر ریسمانی ما باید رابطی مشابه `thread::spawn` داشته باشد. علاوه بر این، ما تابع `execute` را پیاده‌سازی خواهیم کرد تا بسته‌بندی‌ای که دریافت می‌کند را بگیرد و آن را به یک ریسمان بیکار در استخر برای اجرا بدهد.

ما متد `execute` را روی `ThreadPool` تعریف خواهیم کرد تا یک بسته‌بندی به‌عنوان پارامتر بگیرد. به یاد بیاورید از بخش «انتقال مقادیر ضبط‌شده از بسته‌بندی و ویژگی‌های Fn» در فصل سیزدهم که می‌توانیم بسته‌بندی‌ها را با سه ویژگی مختلف به‌عنوان پارامتر بگیریم: `Fn`، `FnMut`، و `FnOnce`. باید تصمیم بگیریم که اینجا از کدام نوع بسته‌بندی استفاده کنیم. می‌دانیم که در نهایت کاری مشابه پیاده‌سازی کتابخانه استاندارد `thread::spawn` انجام خواهیم داد، بنابراین می‌توانیم ببینیم که امضای `thread::spawn` چه محدودیت‌هایی روی پارامتر خود دارد. مستندات به ما موارد زیر را نشان می‌دهد:

```rust
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T,
        F: Send + 'static,
        T: Send + 'static,
```

پارامتر نوع `F` همان چیزی است که ما اینجا به آن اهمیت می‌دهیم؛ پارامتر نوع `T` به مقدار بازگشتی مربوط است، و ما به آن اهمیت نمی‌دهیم. می‌بینیم که `spawn` از `FnOnce` به‌عنوان محدودیت ویژگی روی `F` استفاده می‌کند. این احتمالاً همان چیزی است که ما هم می‌خواهیم، زیرا در نهایت آرگومانی که در `execute` دریافت می‌کنیم را به `spawn` پاس خواهیم داد. می‌توانیم مطمئن‌تر باشیم که `FnOnce` ویژگی‌ای است که می‌خواهیم استفاده کنیم زیرا ریسمان برای اجرای یک درخواست فقط یک بار بسته‌بندی آن درخواست را اجرا خواهد کرد، که با `Once` در `FnOnce` مطابقت دارد.

پارامتر نوع `F` همچنین دارای محدودیت ویژگی `Send` و محدودیت طول عمر `'static` است، که در موقعیت ما مفید هستند: ما به `Send` نیاز داریم تا بسته‌بندی را از یک ریسمان به ریسمان دیگر منتقل کنیم و `'static` زیرا نمی‌دانیم ریسمان چقدر طول خواهد کشید تا اجرا شود. بیایید یک متد `execute` روی `ThreadPool` ایجاد کنیم که یک پارامتر عمومی از نوع `F` با این محدودیت‌ها را بگیرد:

**فایل: src/lib.rs**

```rust
impl ThreadPool {
    // --snip--
    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
    }
}
```

ما همچنان از `()` بعد از `FnOnce` استفاده می‌کنیم زیرا این `FnOnce` نشان‌دهنده یک بسته‌بندی است که هیچ پارامتری نمی‌گیرد و نوع واحد `()` را برمی‌گرداند. درست مانند تعریف‌های تابع، نوع بازگشتی می‌تواند از امضا حذف شود، اما حتی اگر پارامتری نداشته باشیم، همچنان به پرانتزها نیاز داریم.

باز هم، این ساده‌ترین پیاده‌سازی متد `execute` است: هیچ کاری انجام نمی‌دهد، اما ما فقط سعی می‌کنیم کد خود را کامپایل کنیم. بیایید دوباره آن را بررسی کنیم:

```
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.24s
```

کامپایل شد! اما توجه کنید که اگر `cargo run` را امتحان کنید و در مرورگر درخواستی انجام دهید، خطاهایی را در مرورگر خواهید دید که در ابتدای فصل دیدیم. کتابخانه ما هنوز بسته‌بندی‌ای که به `execute` پاس داده شده را فراخوانی نمی‌کند!

**توجه**: ضرب‌المثلی که ممکن است درباره زبان‌هایی با کامپایلرهای سخت‌گیر مانند Haskell و Rust بشنوید این است که «اگر کد کامپایل شود، کار می‌کند.» اما این ضرب‌المثل همیشه درست نیست. پروژه ما کامپایل می‌شود، اما مطلقاً هیچ کاری انجام نمی‌دهد! اگر در حال ساخت یک پروژه واقعی و کامل بودیم، حالا زمان خوبی برای شروع نوشتن آزمون‌های واحدی بود تا بررسی کنیم که کد نه‌تنها کامپایل می‌شود بلکه رفتار مورد نظر ما را دارد.

**ملاحظه**: چه چیزی اینجا متفاوت می‌بود اگر ما به‌جای یک بسته‌بندی قصد اجرای یک آینده (future) را داشتیم؟

## اعتبارسنجی تعداد ریسمان‌ها در `new`

ما با پارامترهای `new` و `execute` هیچ کاری انجام نمی‌دهیم. بیایید بدنه این توابع را با رفتار مورد نظرمان پیاده‌سازی کنیم. برای شروع، بیایید درباره `new` فکر کنیم. قبلاً نوع بدون علامت را برای پارامتر `size` انتخاب کردیم زیرا یک استخر با تعداد منفی ریسمان‌ها معنایی ندارد. با این حال، یک استخر با صفر ریسمان هم معنایی ندارد، اما صفر یک مقدار کاملاً معتبر `usize` است. ما کدی اضافه خواهیم کرد تا بررسی کند که `size` بزرگ‌تر از صفر است قبل از اینکه یک نمونه `ThreadPool` برگردانیم و اگر صفر دریافت کند با استفاده از ماکرو `assert!` برنامه را به پنیک بیندازیم، همان‌طور که در Listing 21-13 نشان داده شده است.

**فایل: src/lib.rs**

```rust
impl ThreadPool {
    /// ایجاد یک ThreadPool جدید.
    ///
    /// اندازه تعداد ریسمان‌ها در استخر است.
    ///
    /// # Panics
    ///
    /// تابع `new` اگر اندازه صفر باشد پنیک خواهد کرد.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        ThreadPool
    }

    // --snip--
}
```

**Listing 21-13: پیاده‌سازی ThreadPool::new برای پنیک در صورت صفر بودن اندازه**

ما همچنین مقداری مستندات برای `ThreadPool` خود با کامنت‌ها مستنداتی اضافه کرده‌ایم. توجه کنید که ما از روش‌های خوب مستندسازی پیروی کردیم با افزودن بخشی که موقعیت‌هایی که تابع ما می‌تواند پنیک کند را مشخص می‌کند، همان‌طور که در فصل چهاردهم بحث کردیم. سعی کنید `cargo doc --open` را اجرا کنید و روی ساختار `ThreadPool` کلیک کنید تا ببینید مستندات تولیدشده برای `new` چگونه به نظر می‌رسند!

به‌جای افزودن ماکرو `assert!` همان‌طور که اینجا انجام دادیم، می‌توانستیم `new` را به `build` تغییر دهیم و یک `Result` برگردانیم مانند کاری که با `Config::build` در پروژه ورودی/خروجی در Listing 12-9 کردیم. اما ما در این مورد تصمیم گرفتیم که تلاش برای ایجاد یک استخر ریسمانی بدون هیچ ریسمانی باید یک خطای غیرقابل بازیابی باشد. اگر احساس جاه‌طلبی می‌کنید، سعی کنید یک تابع به نام `build` با امضای زیر بنویسید تا با تابع `new` مقایسه کنید:

```rust
pub fn build(size: usize) -> Result<ThreadPool, PoolCreationError> {
```

## ایجاد فضا برای ذخیره ریسمان‌ها

حالا که راهی برای اطمینان از داشتن تعداد معتبری از ریسمان‌ها برای ذخیره در استخر داریم، می‌توانیم آن ریسمان‌ها را ایجاد کنیم و آن‌ها را در ساختار `ThreadPool` قبل از بازگرداندن ساختار ذخیره کنیم. اما چگونه یک ریسمان را «ذخیره» کنیم؟ بیایید نگاهی دیگر به امضای `thread::spawn` بیندازیم:

```rust
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T,
        F: Send + 'static,
        T: Send + 'static,
```

تابع `spawn` یک `JoinHandle<T>` برمی‌گرداند، که `T` نوع بازگشتی بسته‌بندی است. بیایید از `JoinHandle` هم استفاده کنیم و ببینیم چه اتفاقی می‌افتد. در مورد ما، بسته‌بندی‌هایی که به استخر ریسمانی پاس می‌دهیم اتصال را مدیریت می‌کنند و چیزی برنمی‌گردانند، بنابراین `T` نوع واحد `()` خواهد بود.

کد موجود در Listing 21-14 کامپایل می‌شود اما هنوز هیچ ریسمانی ایجاد نمی‌کند. ما تعریف `ThreadPool` را تغییر داده‌ایم تا یک بردار از نمونه‌های `thread::JoinHandle<()>` نگه دارد، بردار را با ظرفیت `size` مقداردهی اولیه کرده‌ایم، یک حلقه `for` تنظیم کرده‌ایم که کدی را برای ایجاد ریسمان‌ها اجرا خواهد کرد، و یک نمونه `ThreadPool` شامل آن‌ها را برگردانده‌ایم.

**فایل: src/lib.rs**

*این کد رفتار مورد نظر را تولید نمی‌کند.*

```rust
use std::thread;

pub struct ThreadPool {
    threads: Vec<thread::JoinHandle<()>>,
}

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let mut threads = Vec::with_capacity(size);

        for _ in 0..size {
            // ایجاد برخی ریسمان‌ها و ذخیره آن‌ها در بردار
        }

        ThreadPool { threads }
    }
    // --snip--
}
```

**Listing 21-14: ایجاد یک بردار برای ThreadPool برای نگه داشتن ریسمان‌ها**

ما `std::thread` را به حوزه در crate کتابخانه‌ای آورده‌ایم زیرا از `thread::JoinHandle` به‌عنوان نوع آیتم‌ها در بردار در `ThreadPool` استفاده می‌کنیم.

هنگامی که یک اندازه معتبر دریافت شد، `ThreadPool` ما یک بردار جدید ایجاد می‌کند که می‌تواند `size` آیتم را نگه دارد. تابع `with_capacity` همان کار `Vec::new` را انجام می‌دهد اما با یک تفاوت مهم: فضای کافی در بردار را از قبل تخصیص می‌دهد. چون می‌دانیم که باید `size` عنصر را در بردار ذخیره کنیم، انجام این تخصیص از قبل کمی کارآمدتر از استفاده از `Vec::new` است، که با افزودن عناصر اندازه خود را تغییر می‌دهد.

وقتی دوباره `cargo check` را اجرا کنید، باید موفق باشد.

## یک ساختار Worker مسئول ارسال کد از ThreadPool به یک ریسمان

ما یک نظر در حلقه `for` در Listing 21-14 درباره ایجاد ریسمان‌ها گذاشتیم. اینجا، ما بررسی خواهیم کرد که چگونه واقعاً ریسمان‌ها را ایجاد کنیم. کتابخانه استاندارد `thread::spawn` را به‌عنوان راهی برای ایجاد ریسمان‌ها فراهم می‌کند، و `thread::spawn` انتظار دارد کدی را دریافت کند که ریسمان باید به محض ایجاد شدن اجرا کند. با این حال، در مورد ما، می‌خواهیم ریسمان‌ها را ایجاد کنیم و آن‌ها را منتظر کدی کنیم که بعداً ارسال خواهیم کرد. پیاده‌سازی ریسمان‌های کتابخانه استاندارد راهی برای انجام این کار شامل نمی‌شود؛ ما باید خودمان آن را پیاده‌سازی کنیم.

ما این رفتار را با معرفی یک ساختار داده جدید بین `ThreadPool` و ریسمان‌ها که این رفتار جدید را مدیریت خواهد کرد پیاده‌سازی خواهیم کرد. ما این ساختار داده را `Worker` خواهیم نامید، که اصطلاحی رایج در پیاده‌سازی‌های استخری است. `Worker` کدی را که باید اجرا شود برمی‌دارد و کد را در ریسمان `Worker` اجرا می‌کند.

به افرادی فکر کنید که در آشپزخانه یک رستوران کار می‌کنند: کارگران منتظر می‌مانند تا سفارشات از مشتریان وارد شود، و سپس مسئول گرفتن آن سفارشات و انجام آن‌ها هستند.

به‌جای ذخیره یک بردار از نمونه‌های `JoinHandle<()>` در استخر ریسمانی، نمونه‌های ساختار `Worker` را ذخیره خواهیم کرد. هر `Worker` یک نمونه واحد `JoinHandle<()>` را ذخیره خواهد کرد. سپس ما یک متد روی `Worker` پیاده‌سازی خواهیم کرد که یک بسته‌بندی کد برای اجرا خواهد گرفت و آن را به ریسمان در حال اجرا برای اجرا ارسال خواهد کرد. همچنین به هر `Worker` یک `id` خواهیم داد تا بتوانیم بین نمونه‌های مختلف `Worker` در استخر هنگام لاگ‌گیری یا دیباگ تمایز قائل شویم.

این فرآیند جدیدی است که هنگام ایجاد یک `ThreadPool` رخ خواهد داد. ما کد ارسال بسته‌بندی به ریسمان را پس از تنظیم `Worker` به این روش پیاده‌سازی خواهیم کرد:

1. تعریف یک ساختار `Worker` که یک `id` و یک `JoinHandle<()>` را نگه می‌دارد.
2. تغییر `ThreadPool` برای نگه داشتن یک بردار از نمونه‌های `Worker`.
3. تعریف یک تابع `Worker::new` که یک شماره `id` می‌گیرد و یک نمونه `Worker` را برمی‌گرداند که `id` و یک ریسمان ایجادشده با یک بسته‌بندی خالی را نگه می‌دارد.
4. در `ThreadPool::new`، از شمارشگر حلقه `for` برای تولید یک `id` استفاده کنید، یک `Worker` جدید با آن `id` ایجاد کنید، و کارگر را در بردار ذخیره کنید.

اگر برای چالش آماده هستید، سعی کنید این تغییرات را خودتان قبل از نگاه کردن به کد در Listing 21-15 پیاده‌سازی کنید.

آماده‌اید؟ اینجاست Listing 21-15 با یک راه برای انجام تغییرات ذکرشده.

**فایل: src/lib.rs**

```rust
use std::thread;

pub struct ThreadPool {
    workers: Vec<Worker>,
}

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id));
        }

        ThreadPool { workers }
    }
    // --snip--
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize) -> Worker {
        let thread = thread::spawn(|| {});

        Worker { id, thread }
    }
}
```

**Listing 21-15: تغییر ThreadPool برای نگه داشتن نمونه‌های Worker به‌جای نگه داشتن مستقیم ریسمان‌ها**

ما نام فیلد روی `ThreadPool` را از `threads` به `workers` تغییر داده‌ایم زیرا حالا نمونه‌های `Worker` را به‌جای نمونه‌های `JoinHandle<()>` نگه می‌دارد. ما از شمارشگر در حلقه `for` به‌عنوان آرگومان به `Worker::new` استفاده می‌کنیم، و هر `Worker` جدید را در بردار به نام `workers` ذخیره می‌کنیم.

کد خارجی (مانند سرور ما در `src/main.rs`) نیازی به دانستن جزئیات پیاده‌سازی مربوط به استفاده از یک ساختار `Worker` در `ThreadPool` ندارد، بنابراین ما ساختار `Worker` و تابع `new` آن را خصوصی می‌کنیم. تابع `Worker::new` از `id` که به آن می‌دهیم استفاده می‌کند و یک نمونه `JoinHandle<()>` را ذخیره می‌کند که با ایجاد یک ریسمان جدید با استفاده از یک بسته‌بندی خالی ایجاد شده است.

**توجه**: اگر سیستم‌عامل نتواند به دلیل کمبود منابع سیستمی ریسمان ایجاد کند، `thread::spawn` پنیک خواهد کرد. این باعث می‌شود کل سرور ما پنیک کند، حتی اگر ایجاد برخی ریسمان‌ها موفق شود. برای سادگی، این رفتار خوب است، اما در یک پیاده‌سازی استخر ریسمانی تولیدی، احتمالاً می‌خواهید از `std::thread::Builder` و متد `spawn` آن که یک `Result` برمی‌گرداند استفاده کنید.

این کد کامپایل خواهد شد و تعداد نمونه‌های `Worker` را که به‌عنوان آرگومان به `ThreadPool::new` مشخص کرده‌ایم ذخیره خواهد کرد. اما ما هنوز بسته‌بندی‌ای که در `execute` دریافت می‌کنیم را پردازش نمی‌کنیم. بیایید بعدی ببینیم چگونه این کار را انجام دهیم.

## ارسال درخواست‌ها به ریسمان‌ها از طریق کانال‌ها

مشکل بعدی که ما به آن خواهیم پرداخت این است که بسته‌بندی‌های داده‌شده به `thread::spawn` مطلقاً هیچ کاری انجام نمی‌دهند. در حال حاضر، ما بسته‌بندی‌ای را که می‌خواهیم در متد `execute` اجرا کنیم دریافت می‌کنیم. اما باید به `thread::spawn` یک بسته‌بندی بدهیم تا هنگام ایجاد هر `Worker` در زمان ایجاد `ThreadPool` اجرا شود.

ما می‌خواهیم ساختارهای `Worker` که به‌تازگی ایجاد کردیم کدی را که باید اجرا شود از یک صف که در `ThreadPool` نگه داشته شده است بردارند و آن کد را به ریسمان خود برای اجرا ارسال کنند.

کانال‌هایی که در فصل شانزدهم درباره آن‌ها آموختیم—یک راه ساده برای ارتباط بین دو ریسمان—برای این مورد استفاده عالی خواهند بود. ما از یک کانال برای عملکرد به‌عنوان صف وظایف استفاده خواهیم کرد، و `execute` یک وظیفه را از `ThreadPool` به نمونه‌های `Worker` ارسال خواهد کرد، که وظیفه را به ریسمان خود ارسال خواهد کرد. اینجاست طرح:

1. `ThreadPool` یک کانال ایجاد خواهد کرد و فرستنده را نگه خواهد داشت.
2. هر `Worker` گیرنده را نگه خواهد داشت.
3. ما یک ساختار جدید `Job` ایجاد خواهیم کرد که بسته‌بندی‌هایی را که می‌خواهیم از طریق کانال ارسال کنیم نگه خواهد داشت.
4. متد `execute` وظیفه‌ای را که می‌خواهد اجرا کند از طریق فرستنده ارسال خواهد کرد.
5. در ریسمان خود، `Worker` روی گیرنده خود حلقه خواهد زد و بسته‌بندی‌های هر وظیفه‌ای که دریافت می‌کند را اجرا خواهد کرد.

بیایید با ایجاد یک کانال در `ThreadPool::new` و نگه داشتن فرستنده در نمونه `ThreadPool` شروع کنیم، همان‌طور که در Listing 21-16 نشان داده شده است. ساختار `Job` برای حالا چیزی نگه نمی‌دارد اما نوع آیتمی خواهد بود که از طریق کانال ارسال می‌کنیم.

**فایل: src/lib.rs**

```rust
use std::{sync::mpsc, thread};

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: mpsc::Sender<Job>,
}

struct Job;

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id));
        }

        ThreadPool { workers, sender }
    }
    // --snip--
}
```

**Listing 21-16: تغییر ThreadPool برای ذخیره فرستنده یک کانال که نمونه‌های Job را ارسال می‌کند**

در `ThreadPool::new`، ما کانال جدید خود را ایجاد می‌کنیم و استخر فرستنده را نگه می‌دارد. این با موفقیت کامپایل خواهد شد.

بیایید سعی کنیم گیرنده کانال را به هر `Worker` هنگام ایجاد کانال توسط استخر ریسمانی پاس دهیم. می‌دانیم که می‌خواهیم از گیرنده در ریسمانی که نمونه‌های `Worker` ایجاد می‌کنند استفاده کنیم، بنابراین به پارامتر گیرنده در بسته‌بندی ارجاع خواهیم داد. کد موجود در Listing 21-17 هنوز کاملاً کامپایل نخواهد شد.

**فایل: src/lib.rs**

<div class="err"> *<img src="img/does_not_compile.svg" > این کد کامپایل نمی‌شود!* </div>

```rust
impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, receiver));
        }

        ThreadPool { workers, sender }
    }
    // --snip--
}

// --snip--

impl Worker {
    fn new(id: usize, receiver: mpsc::Receiver<Job>) -> Worker {
        let thread = thread::spawn(|| {
            receiver;
        });

        Worker { id, thread }
    }
}
```

**Listing 21-17: پاس دادن گیرنده به هر Worker**

ما تغییرات کوچک و ساده‌ای انجام داده‌ایم: گیرنده را به `Worker::new` پاس می‌دهیم، و سپس از آن در بسته‌بندی استفاده می‌کنیم.

وقتی این کد را بررسی می‌کنیم، این خطا را دریافت می‌کنیم:

```
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0382]: use of moved value: `receiver`
  --> src/lib.rs:26:42
   |
21 |         let (sender, receiver) = mpsc::channel();
   |                      -------- move occurs because `receiver` has type `std::sync::mpsc::Receiver<Job>`, which does not implement the `Copy` trait
...
25 |         for id in 0..size {
   |         ----------------- inside of this loop
26 |             workers.push(Worker::new(id, receiver));
   |                                          ^^^^^^^^ value moved here, in previous iteration of loop
   |
note: consider changing this parameter type in method `new` to borrow instead if owning the value isn't necessary
  --> src/lib.rs:47:33
   |
47 |     fn new(id: usize, receiver: mpsc::Receiver<Job>) -> Worker {
   |        --- in this method       ^^^^^^^^^^^^^^^^^^^ this parameter takes ownership of the value
help: consider moving the expression out of the loop so it is only moved once
   |
25 ~         let mut value = Worker::new(id, receiver);
26 ~         for id in 0..size {
27 ~             workers.push(value);
   |

For more information about this error, try `rustc --explain E0382`.
error: could not compile `hello` (lib) due to 1 previous error
```

کد سعی دارد `receiver` را به چندین نمونه `Worker` پاس دهد. این کار نمی‌کند، همان‌طور که از فصل شانزدهم به یاد می‌آورید: پیاده‌سازی کانال که Rust فراهم می‌کند چندتولیدکننده، تک‌مصرف‌کننده است. این به این معناست که نمی‌توانیم فقط انتهای مصرف‌کننده کانال را کلون کنیم تا این کد را برطرف کنیم. همچنین نمی‌خواهیم یک پیام را چندین بار به چندین مصرف‌کننده ارسال کنیم؛ ما یک لیست از پیام‌ها با چندین نمونه `Worker` می‌خواهیم به‌گونه‌ای که هر پیام فقط یک بار پردازش شود.

علاوه بر این، برداشتن یک وظیفه از صف کانال شامل تغییر `receiver` است، بنابراین ریسمان‌ها به روشی امن برای اشتراک‌گذاری و تغییر `receiver` نیاز دارند؛ در غیر این صورت، ممکن است شرایط رقابتی (race conditions) دریافت کنیم (همان‌طور که در فصل شانزدهم پوشش داده شد).

به یاد بیاورید اشاره‌گرهای هوشمند ایمن برای ریسمان که در فصل شانزدهم بحث کردیم: برای اشتراک مالکیت بین چندین ریسمان و اجازه دادن به ریسمان‌ها برای تغییر مقدار، باید از `Arc<Mutex<T>>` استفاده کنیم. نوع `Arc` به چندین نمونه `Worker` اجازه می‌دهد مالکیت گیرنده را داشته باشند، و `Mutex` اطمینان می‌دهد که فقط یک `Worker` در یک زمان وظیفه‌ای از گیرنده دریافت کند. Listing 21-18 تغییراتی که باید انجام دهیم را نشان می‌دهد.

**فایل: src/lib.rs**

```rust
use std::{
    sync::{Arc, Mutex, mpsc},
    thread,
};
// --snip--

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool { workers, sender }
    }

    // --snip--
}

// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        // --snip--
    }
}
```

**Listing 21-18: اشتراک گیرنده بین نمونه‌های Worker با استفاده از Arc و Mutex**

در `ThreadPool::new`، ما گیرنده را در یک `Arc` و یک `Mutex` قرار می‌دهیم. برای هر `Worker` جدید، ما `Arc` را کلون می‌کنیم تا تعداد ارجاع را افزایش دهیم تا نمونه‌های `Worker` بتوانند مالکیت گیرنده را به اشتراک بگذارند.

با این تغییرات، کد کامپایل می‌شود! داریم به هدف نزدیک می‌شویم!

## پیاده‌سازی متد execute

بیایید در نهایت متد `execute` را روی `ThreadPool` پیاده‌سازی کنیم. همچنین `Job` را از یک ساختار به یک نام مستعار نوع برای یک شیء ویژگی تغییر خواهیم داد که نوع بسته‌بندی‌ای که `execute` دریافت می‌کند را نگه می‌دارد. همان‌طور که در بخش «ایجاد نام‌های مستعار نوع با نام‌های مستعار نوع» در فصل بیستم بحث کردیم، نام‌های مستعار نوع به ما امکان می‌دهند تا انواع طولانی را برای سهولت استفاده کوتاه‌تر کنیم. به Listing 21-19 نگاه کنید.

**فایل: src/lib.rs**

```rust
// --snip--

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    // --snip--

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.send(job).unwrap();
    }
}

// --snip--
```

**Listing 21-19: ایجاد یک نام مستعار نوع Job برای یک Box که هر بسته‌بندی را نگه می‌دارد و سپس ارسال وظیفه از طریق کانال**

پس از ایجاد یک نمونه جدید `Job` با استفاده از بسته‌بندی‌ای که در `execute` دریافت می‌کنیم، آن وظیفه را از طریق انتهای فرستنده کانال ارسال می‌کنیم. ما روی `send` از `unwrap` استفاده می‌کنیم برای موردی که ارسال شکست بخورد. این ممکن است اتفاق بیفتد، برای مثال، اگر تمام ریسمان‌های ما را از اجرا متوقف کنیم، به این معنا که انتهای گیرنده دریافت پیام‌های جدید را متوقف کرده است. در حال حاضر، ما نمی‌توانیم ریسمان‌های خود را از اجرا متوقف کنیم: ریسمان‌های ما تا زمانی که استخر وجود دارد به اجرا ادامه می‌دهند. دلیل استفاده از `unwrap` این است که می‌دانیم مورد شکست رخ نخواهد داد، اما کامپایلر این را نمی‌داند.

اما هنوز کارمان تمام نشده است! در `Worker`، بسته‌بندی‌ای که به `thread::spawn` پاس داده شده هنوز فقط به انتهای گیرنده کانال ارجاع می‌دهد. در عوض، ما نیاز داریم که بسته‌بندی به‌صورت بی‌پایان حلقه بزند، از انتهای گیرنده کانال یک وظیفه بخواهد و وظیفه را وقتی دریافت کرد اجرا کند. بیایید تغییر نشان‌داده‌شده در Listing 21-20 را در `Worker::new` اعمال کنیم.

**فایل: src/lib.rs**

```rust
// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            loop {
                let job = receiver.lock().unwrap().recv().unwrap();

                println!("کارگر {} یک وظیفه دریافت کرد؛ در حال اجرا.", id); // Worker {} got a job; executing.

                job();
            }
        });

        Worker { id, thread }
    }
}
```

**Listing 21-20: دریافت و اجرای وظایف در ریسمان نمونه Worker**

در اینجا، ابتدا روی گیرنده `lock` را فراخوانی می‌کنیم تا قفل را به دست آوریم، و سپس `unwrap` را فراخوانی می‌کنیم تا در صورت بروز هر خطا پنیک کنیم. کسب قفل ممکن است شکست بخورد اگر قفل در حالت مسموم (poisoned) باشد، که می‌تواند وقتی ریسمان دیگری در حالی که قفل را نگه داشته پنیک کند به‌جای آزاد کردن قفل رخ دهد. در این موقعیت، فراخوانی `unwrap` برای پنیک کردن این ریسمان اقدام درستی است. اگر می‌خواهید، آزادانه این `unwrap` را به یک `expect` با یک پیام خطای معنادار برای خود تغییر دهید.

اگر قفل روی قفل را به دست آوریم، `recv` را فراخوانی می‌کنیم تا یک `Job` از کانال دریافت کنیم. یک `unwrap` نهایی هر خطایی را اینجا هم رد می‌کند، که ممکن است رخ دهد اگر ریسمانی که فرستنده را نگه می‌دارد خاموش شده باشد، مشابه اینکه چگونه متد `send` اگر گیرنده خاموش شود `Err` برمی‌گرداند.

فراخوانی به `recv` بلاک می‌کند، بنابراین اگر هنوز وظیفه‌ای وجود نداشته باشد، ریسمان فعلی منتظر خواهد ماند تا یک وظیفه در دسترس شود. `Mutex<T>` اطمینان می‌دهد که فقط یک ریسمان `Worker` در یک زمان سعی در درخواست یک وظیفه دارد.

استخر ریسمانی ما حالا در حالت کاری است! آن را با `cargo run` اجرا کنید و چند درخواست انجام دهید:

```
$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
warning: field `workers` is never read
 --> src/lib.rs:7:5
  |
6 | pub struct ThreadPool {
  |            ---------- field in this struct
7 |     workers: Vec<Worker>,
  |     ^^^^^^^
  |
  = note: `#[warn(dead_code)]` on by default

warning: fields `id` and `thread` are never read
  --> src/lib.rs:48:5
   |
47 | struct Worker {
   |        ------ fields in this struct
48 |     id: usize,
   |     ^^
49 |     thread: thread::JoinHandle<()>,
   |     ^^^^^^

warning: `hello` (lib) generated 2 warnings
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 4.91s
     Running `target/debug/hello`
کارگر 0 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 2 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 1 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 3 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 0 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 2 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 1 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 3 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 0 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 2 یک وظیفه دریافت کرد؛ در حال اجرا.
```

موفقیت! ما حالا یک استخر ریسمانی داریم که اتصالات را به‌صورت ناهمزمان اجرا می‌کند. هرگز بیش از چهار ریسمان ایجاد نمی‌شود، بنابراین سیستم ما اگر سرور تعداد زیادی درخواست دریافت کند بیش از حد بارگذاری نخواهد شد. اگر درخواستی به `/sleep` انجام دهیم، سرور قادر خواهد بود درخواست‌های دیگر را با اجرای آن‌ها توسط یک ریسمان دیگر ارائه دهد.

**توجه**: اگر `/sleep` را در چندین پنجره مرورگر به‌صورت همزمان باز کنید، ممکن است آن‌ها یک‌به‌یک در فواصل پنج‌ثانیه‌ای بارگذاری شوند. برخی مرورگرهای وب چندین نمونه از یک درخواست را به دلایل کش‌سازی به‌صورت متوالی اجرا می‌کنند. این محدودیت به دلیل وب سرور ما نیست.

اکنون زمان خوبی است که مکث کنیم و در نظر بگیریم که کد در Listing‌های 21-18، 21-19، و 21-20 اگر به‌جای بسته‌بندی از آینده‌ها (futures) برای کار استفاده می‌کردیم چگونه متفاوت می‌بود. چه نوع‌هایی تغییر می‌کردند؟ امضاهای متد چگونه متفاوت می‌بودند، اگر اصلاً تفاوتی داشتند؟ کدام بخش‌های کد یکسان باقی می‌ماندند؟

پس از یادگیری درباره حلقه `while let` در فصل‌های هفدهم و هجدهم، ممکن است تعجب کنید که چرا ما کد ریسمان کارگر را همان‌طور که در Listing 21-21 نشان داده شده ننوشتیم.

**فایل: src/lib.rs**

*این کد رفتار مورد نظر را تولید نمی‌کند.*

```rust
// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            while let Ok(job) = receiver.lock().unwrap().recv() {
                println!("کارگر {} یک وظیفه دریافت کرد؛ در حال اجرا.", id); // Worker {} got a job; executing.

                job();
            }
        });

        Worker { id, thread }
    }
}
```

**Listing 21-21: یک پیاده‌سازی جایگزین از Worker::new با استفاده از while let**

این کد کامپایل می‌شود و اجرا می‌شود اما رفتار ریسمانی مورد نظر را ایجاد نمی‌کند: یک درخواست کند همچنان باعث می‌شود درخواست‌های دیگر منتظر پردازش شوند. دلیل آن تا حدی ظریف است: ساختار `Mutex` هیچ متد عمومی `unlock` ندارد زیرا مالکیت قفل بر اساس طول عمر `MutexGuard<T>` در `LockResult<MutexGuard<T>>` که متد `lock` برمی‌گرداند است. در زمان کامپایل، بررسی‌کننده قرض (borrow checker) سپس می‌تواند قانونی را اعمال کند که منبعی که توسط یک `Mutex` محافظت می‌شود نمی‌تواند دسترسی پیدا کند مگر اینکه قفل را نگه داریم. با این حال، این پیاده‌سازی همچنین می‌تواند منجر به نگه‌داری قفل طولانی‌تر از آنچه در نظر گرفته شده است اگر مراقب طول عمر `MutexGuard<T>` نباشیم.

کدی که در Listing 21-20 با استفاده از `let job = receiver.lock().unwrap().recv().unwrap();` کار می‌کند زیرا با `let`، هر مقدار موقتی که در عبارت سمت راست علامت مساوی استفاده شده است بلافاصله وقتی بیانیه `let` به پایان می‌رسد حذف می‌شود. با این حال، `while let` (و `if let` و `match`) مقادیر موقتی را تا پایان بلوک مرتبط حذف نمی‌کند. در Listing 21-21، قفل در طول فراخوانی به `job()` نگه داشته می‌شود، به این معنا که نمونه‌های دیگر `Worker` نمی‌توانند وظایف را دریافت کنند.