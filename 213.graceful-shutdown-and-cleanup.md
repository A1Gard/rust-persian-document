# خاموشی آرام و تمیز کردن

کد موجود در Listing 21-20 همان‌طور که قصد داشتیم از طریق استفاده از یک استخر ریسمانی به درخواست‌ها به‌صورت ناهمزمان پاسخ می‌دهد. ما چند هشدار درباره فیلدهای `workers`، `id`، و `thread` دریافت می‌کنیم که به‌طور مستقیم استفاده نمی‌کنیم و این به ما یادآوری می‌کند که هیچ چیزی را تمیز نمی‌کنیم. وقتی از روش کمتر ظریف `ctrl-c` برای متوقف کردن ریسمان اصلی استفاده می‌کنیم، تمام ریسمان‌های دیگر نیز بلافاصله متوقف می‌شوند، حتی اگر در حال ارائه یک درخواست باشند.

در ادامه، ما ویژگی `Drop` را پیاده‌سازی خواهیم کرد تا روی هر یک از ریسمان‌های موجود در استخر `join` را فراخوانی کنیم تا بتوانند درخواست‌هایی که در حال کار روی آن‌ها هستند را قبل از بسته شدن به پایان برسانند. سپس راهی برای گفتن به ریسمان‌ها پیاده‌سازی خواهیم کرد که باید پذیرش درخواست‌های جدید را متوقف کنند و خاموش شوند. برای دیدن این کد در عمل، سرور خود را تغییر خواهیم داد تا فقط دو درخواست را قبل از خاموش کردن آرام استخر ریسمانی خود بپذیرد.

یک نکته برای توجه در حین پیشرفت: هیچ‌کدام از این‌ها روی بخش‌های کدی که مدیریت اجرای بسته‌بندی‌ها را بر عهده دارند تأثیر نمی‌گذارد، بنابراین همه چیز اینجا دقیقاً همان‌طور خواهد بود اگر ما از یک استخر ریسمانی برای یک زمان‌اجرای ناهمزمان استفاده می‌کردیم.

## پیاده‌سازی ویژگی Drop روی ThreadPool

بیایید با پیاده‌سازی `Drop` روی استخر ریسمانی خود شروع کنیم. وقتی استخر حذف می‌شود، تمام ریسمان‌های ما باید `join` شوند تا مطمئن شویم کار خود را به پایان می‌رسانند. Listing 21-22 اولین تلاش برای پیاده‌سازی `Drop` را نشان می‌دهد؛ این کد هنوز کاملاً کار نخواهد کرد.

**فایل: src/lib.rs**

*این کد کامپایل نمی‌شود!*

```rust
impl Drop for ThreadPool {
    fn drop(&mut self) {
        for worker in &mut self.workers {
            println!("در حال خاموش کردن کارگر {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}
```

**Listing 21-22: پیوستن به هر ریسمان وقتی استخر ریسمانی از حوزه خارج می‌شود**

ابتدا، روی هر یک از کارگران استخر ریسمانی حلقه می‌کنیم. ما از `&mut` برای این استفاده می‌کنیم زیرا `self` یک ارجاع قابل تغییر است، و همچنین باید بتوانیم `worker` را تغییر دهیم. برای هر کارگر، پیامی چاپ می‌کنیم که می‌گوید این نمونه خاص `Worker` در حال خاموش شدن است، و سپس `join` را روی ریسمان آن نمونه `Worker` فراخوانی می‌کنیم. اگر فراخوانی به `join` شکست بخورد، از `unwrap` استفاده می‌کنیم تا Rust پنیک کند و به یک خاموشی غیرآرام برود.

این خطایی است که هنگام کامپایل این کد دریافت می‌کنیم:

```
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0507]: cannot move out of `worker.thread` which is behind a mutable reference
    --> src/lib.rs:52:13
     |
52   |             worker.thread.join().unwrap();
     |             ^^^^^^^^^^^^^ ------ `worker.thread` moved due to this method call
     |             |
     |             move occurs because `worker.thread` has type `JoinHandle<()>`, which does not implement the `Copy` trait
     |
note: `JoinHandle::<T>::join` takes ownership of the receiver `self`, which moves `worker.thread`
    --> file:///home/.rustup/toolchains/1.85/lib/rustlib/src/rust/library/std/src/thread/mod.rs:1876:17
     |
1876 |     pub fn join(self) -> Result<T> {
     |                 ^^^^

For more information about this error, try `rustc --explain E0507`.
error: could not compile `hello` (lib) due to 1 previous error
```

این خطا به ما می‌گوید که نمی‌توانیم `join` را فراخوانی کنیم زیرا فقط یک قرض قابل تغییر از هر کارگر داریم و `join` مالکیت آرگومان خود را می‌گیرد. برای حل این مشکل، باید ریسمان را از نمونه `Worker` که مالک `thread` است خارج کنیم تا `join` بتواند ریسمان را مصرف کند. یکی از راه‌ها برای انجام این کار استفاده از همان روشی است که در Listing 18-15 انجام دادیم. اگر `Worker` یک `Option<thread::JoinHandle<()>>` نگه دارد، می‌توانیم متد `take` را روی `Option` فراخوانی کنیم تا مقدار را از نوع `Some` خارج کنیم و یک نوع `None` را در جای آن بگذاریم. به عبارت دیگر، یک `Worker` که در حال اجرا است یک نوع `Some` در `thread` خواهد داشت، و وقتی بخواهیم یک `Worker` را تمیز کنیم، `Some` را با `None` جایگزین می‌کنیم تا `Worker` ریسمانی برای اجرا نداشته باشد.

با این حال، این تنها زمانی پیش می‌آید که `Worker` را حذف کنیم. در ازای آن، باید در هر جایی که به `worker.thread` دسترسی داریم با یک `Option<thread::JoinHandle<()>>` سر و کار داشته باشیم. Rust ادیوماتیک از `Option` بسیار استفاده می‌کند، اما وقتی متوجه می‌شوید که چیزی را که می‌دانید همیشه وجود خواهد داشت در `Option` به‌عنوان یک راه‌حل موقت می‌پیچید، بهتر است به دنبال رویکردهای جایگزین باشید. این‌ها می‌توانند کد شما را تمیزتر و کمتر مستعد خطا کنند.

در این مورد، یک جایگزین بهتر وجود دارد: متد `Vec::drain`. این متد یک پارامتر محدوده را می‌پذیرد تا مشخص کند کدام آیتم‌ها را از `Vec` حذف کند، و یک تکرارگر از آن آیتم‌ها را برمی‌گرداند. انتقال نحو محدوده `..` تمام مقادیر را از `Vec` حذف خواهد کرد.

بنابراین باید پیاده‌سازی `drop` برای `ThreadPool` را به این صورت به‌روزرسانی کنیم:

**فایل: src/lib.rs**

```rust
impl Drop for ThreadPool {
    fn drop(&mut self) {
        for worker in self.workers.drain(..) {
            println!("در حال خاموش کردن کارگر {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}
```

این خطای کامپایلر را برطرف می‌کند و نیازی به تغییرات دیگری در کد ما ندارد.

## علامت‌دهی به ریسمان‌ها برای توقف گوش دادن به وظایف

با تمام تغییراتی که انجام داده‌ایم، کد ما بدون هیچ هشداری کامپایل می‌شود. با این حال، خبر بد این است که این کد هنوز آن‌طور که ما می‌خواهیم کار نمی‌کند. کلید در منطق بسته‌بندی‌هایی است که توسط ریسمان‌های نمونه‌های `Worker` اجرا می‌شوند: در حال حاضر، ما `join` را فراخوانی می‌کنیم، اما این ریسمان‌ها را خاموش نمی‌کند زیرا آن‌ها به‌صورت بی‌پایان به دنبال وظایف حلقه می‌زنند. اگر سعی کنیم `ThreadPool` خود را با پیاده‌سازی فعلی `drop` حذف کنیم، ریسمان اصلی برای همیشه بلاک خواهد شد، در انتظار اتمام اولین ریسمان.

برای رفع این مشکل، به تغییر در پیاده‌سازی `drop` برای `ThreadPool` و سپس تغییر در حلقه `Worker` نیاز خواهیم داشت.

ابتدا پیاده‌سازی `drop` برای `ThreadPool` را تغییر خواهیم داد تا قبل از انتظار برای اتمام ریسمان‌ها، فرستنده را به‌صراحت حذف کنیم. Listing 21-23 تغییرات برای `ThreadPool` را برای حذف صریح فرستنده نشان می‌دهد. برخلاف `thread`، اینجا باید از یک `Option` استفاده کنیم تا بتوانیم `sender` را با `Option::take` از `ThreadPool` خارج کنیم.

**فایل: src/lib.rs**

*این کد رفتار مورد نظر را تولید نمی‌کند.*

```rust
pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: Option<mpsc::Sender<Job>>,
}
// --snip--
impl ThreadPool {
    pub fn new(size: usize) -> ThreadPool {
        // --snip--

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        drop(self.sender.take());

        for worker in self.workers.drain(..) {
            println!("در حال خاموش کردن کارگر {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}
```

**Listing 21-23: حذف صریح فرستنده قبل از پیوستن به ریسمان‌های Worker**

حذف `sender` کانال را می‌بندد، که نشان می‌دهد پیام‌های بیشتری ارسال نخواهند شد. وقتی این اتفاق می‌افتد، تمام فراخوانی‌های `recv` که نمونه‌های `Worker` در حلقه بی‌پایان انجام می‌دهند یک خطا برمی‌گردانند. در Listing 21-24، ما حلقه `Worker` را تغییر می‌دهیم تا در این مورد به‌صورت آرام از حلقه خارج شود، به این معنا که وقتی پیاده‌سازی `drop` برای `ThreadPool` روی آن‌ها `join` را فراخوانی می‌کند، ریسمان‌ها تمام خواهند شد.

**فایل: src/lib.rs**

```rust
impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            loop {
                let message = receiver.lock().unwrap().recv();

                match message {
                    Ok(job) => {
                        println!("کارگر {} یک وظیفه دریافت کرد؛ در حال اجرا.", id);

                        job();
                    }
                    Err(_) => {
                        println!("کارگر {} قطع ارتباط شد؛ در حال خاموش شدن.", id);
                        break;
                    }
                }
            }
        });

        Worker { id, thread }
    }
}
```

**Listing 21-24: خروج صریح از حلقه وقتی recv خطا برمی‌گرداند**

برای دیدن این کد در عمل، بیایید `main` را تغییر دهیم تا فقط دو درخواست را قبل از خاموش کردن آرام سرور بپذیرد، همان‌طور که در Listing 21-25 نشان داده شده است.

**فایل: src/main.rs**

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming().take(2) {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }

    println!("در حال خاموش شدن.");
}
```

**Listing 21-25: خاموش کردن سرور پس از ارائه دو درخواست با خروج از حلقه**

شما نمی‌خواهید یک وب سرور واقعی فقط پس از ارائه دو درخواست خاموش شود. این کد فقط نشان می‌دهد که خاموشی آرام و تمیز کردن به درستی کار می‌کند.

متد `take` در ویژگی `Iterator` تعریف شده است و تکرار را حداکثر به دو آیتم اول محدود می‌کند. `ThreadPool` در پایان `main` از حوزه خارج خواهد شد، و پیاده‌سازی `drop` اجرا خواهد شد.

سرور را با `cargo run` شروع کنید، و سه درخواست انجام دهید. درخواست سوم باید خطا بدهد، و در ترمینال شما باید خروجی مشابه این را ببینید:

```
$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.41s
     Running `target/debug/hello`
کارگر 0 یک وظیفه دریافت کرد؛ در حال اجرا.
در حال خاموش شدن.
در حال خاموش کردن کارگر 0
کارگر 3 یک وظیفه دریافت کرد؛ در حال اجرا.
کارگر 1 قطع ارتباط شد؛ در حال خاموش شدن.
کارگر 2 قطع ارتباط شد؛ در حال خاموش شدن.
کارگر 3 قطع ارتباط شد؛ در حال خاموش شدن.
کارگر 0 قطع ارتباط شد؛ در حال خاموش شدن.
در حال خاموش کردن کارگر 1
در حال خاموش کردن کارگر 2
در حال خاموش کردن کارگر 3
```

ممکن است ترتیب متفاوتی از شناسه‌های کارگر و پیام‌های چاپ‌شده را ببینید. می‌توانیم از پیام‌ها ببینیم که این کد چگونه کار می‌کند: نمونه‌های کارگر 0 و 3 دو درخواست اول را دریافت کردند. سرور پس از اتصال دوم پذیرش اتصالات را متوقف کرد، و پیاده‌سازی `Drop` روی `ThreadPool` قبل از اینکه کارگر 3 حتی وظیفه خود را شروع کند آغاز به اجرا می‌کند. حذف `sender` تمام نمونه‌های کارگر را قطع می‌کند و به آن‌ها می‌گوید که خاموش شوند. نمونه‌های کارگر هر کدام هنگام قطع ارتباط پیامی چاپ می‌کنند، و سپس استخر ریسمانی روی هر ریسمان کارگر `join` را فراخوانی می‌کند تا منتظر اتمام آن‌ها بماند.

یک جنبه جالب از این اجرای خاص را توجه کنید: `ThreadPool` فرستنده را حذف کرد، و قبل از اینکه هیچ کارگری خطایی دریافت کند، ما سعی کردیم به کارگر 0 بپیوندیم. کارگر 0 هنوز از `recv` خطایی دریافت نکرده بود، بنابراین ریسمان اصلی منتظر اتمام کارگر 0 بلاک شد. در این میان، کارگر 3 یک وظیفه دریافت کرد و سپس تمام ریسمان‌ها خطا دریافت کردند. وقتی کارگر 0 تمام شد، ریسمان اصلی منتظر اتمام بقیه نمونه‌های کارگر ماند. در آن زمان، همه آن‌ها از حلقه‌های خود خارج شده و متوقف شده بودند.

تبریک می‌گویم! ما حالا پروژه خود را کامل کرده‌ایم؛ ما یک وب سرور پایه داریم که از یک استخر ریسمانی برای پاسخ‌گویی ناهمزمان استفاده می‌کند. ما قادر به انجام خاموشی آرام سرور هستیم، که تمام ریسمان‌های موجود در استخر را تمیز می‌کند.

در اینجا کد کامل برای مرجع آورده شده است:

**فایل: src/main.rs**

```rust
use hello::ThreadPool;
use std::{
    fs,
    io::{BufReader, prelude::*},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};

fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming().take(2) {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }

    println!("در حال خاموش شدن.");
}

fn handle_connection(mut stream: TcpStream) {
    let buf_reader = BufReader::new(&stream);
    let request_line = buf_reader.lines().next().unwrap().unwrap();

    let (status_line, filename) = match &request_line[..] {
        "GET / HTTP/1.1" => ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" => {
            thread::sleep(Duration::from_secs(5));
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ => ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    let contents = fs::read_to_string(filename).unwrap();
    let length = contents.len();

    let response =
        format!("{status_line}\r\nContent-Length: {length}\r\n\r\n{contents}");

    stream.write_all(response.as_bytes()).unwrap();
}
```

**فایل: src/lib.rs**

```rust
use std::{
    sync::{Arc, Mutex, mpsc},
    thread,
};

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: Option<mpsc::Sender<Job>>,
}

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    /// ایجاد یک ThreadPool جدید.
    ///
    /// اندازه تعداد ریسمان‌ها در استخر است.
    ///
    /// # Panics
    ///
    /// تابع `new` اگر اندازه صفر باشد پنیک خواهد کرد.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        drop(self.sender.take());

        for worker in self.workers.drain(..) {
            println!("در حال خاموش کردن کارگر {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            loop {
                let message = receiver.lock().unwrap().recv();

                match message {
                    Ok(job) => {
                        println!("کارگر {} یک وظیفه دریافت کرد؛ در حال اجرا.", id);

                        job();
                    }
                    Err(_) => {
                        println!("کارگر {} قطع ارتباط شد؛ در حال خاموش شدن.", id);
                        break;
                    }
                }
            }
        });

        Worker {
            id,
            thread,
        }
    }
}
```

ما می‌توانیم کارهای بیشتری اینجا انجام دهیم! اگر می‌خواهید به بهبود این پروژه ادامه دهید، در اینجا چند ایده آورده شده است:

- مستندات بیشتری به `ThreadPool` و متدهای عمومی آن اضافه کنید.
- آزمون‌هایی از عملکرد کتابخانه اضافه کنید.
- فراخوانی‌های `unwrap` را به مدیریت خطای قوی‌تر تغییر دهید.
- از `ThreadPool` برای انجام وظیفه‌ای غیر از ارائه درخواست‌های وب استفاده کنید.
- یک crate استخر ریسمانی را در crates.io پیدا کنید و یک وب سرور مشابه را با استفاده از آن crate پیاده‌سازی کنید. سپس API و استحکام آن را با استخر ریسمانی که ما پیاده‌سازی کردیم مقایسه کنید.

## خلاصه

خوب انجام دادید! شما به انتهای کتاب رسیدید! ما از شما برای همراهی با ما در این تور از Rust تشکر می‌کنیم. شما حالا آماده هستید تا پروژه‌های Rust خود را پیاده‌سازی کنید و به پروژه‌های دیگران کمک کنید. به خاطر داشته باشید که یک جامعه خوش‌آمدگوی از دیگر Rustacean‌ها وجود دارد که دوست دارند به شما در هر چالشی که در مسیر Rust خود با آن مواجه می‌شوید کمک کنند.

**ملاحظه درباره آینده‌ها (Futures)**: همان‌طور که در متن اشاره شد، اگر ما به‌جای بسته‌بندی‌ها از آینده‌ها برای کار استفاده می‌کردیم، بخش‌هایی از کد تغییر می‌کرد، اما بخش‌هایی نیز یکسان می‌ماندند. برای مثال:

- **تغییرات نوع**: نوع `Job` به‌جای `Box<dyn FnOnce() + Send + 'static>` ممکن است شامل یک نوع آینده مانند `Box<dyn Future<Output = ()> + Send + 'static>` باشد، و ما نیاز به استفاده از یک زمان‌اجرای ناهمزمان (مانند `tokio` یا `async-std`) برای اجرای آینده‌ها داشتیم.
- **امضاهای متد**: امضای متد `execute` ممکن است نیاز به مشخص کردن اینکه آرگومان یک آینده است داشته باشد، و ما باید آینده را به زمان‌اجرا برای اجرا بفرستیم. با این حال، رابط سطح بالا (گرفتن یک کار و ارسال آن برای اجرا) احتمالاً مشابه باقی می‌ماند.
- **بخش‌های یکسان**: منطق سطح بالا برای مدیریت کارگران، ارسال وظایف از طریق کانال‌ها، و خاموشی آرام تا حد زیادی یکسان باقی می‌ماند، زیرا این‌ها مفاهیم عمومی مدیریت وظایف هستند، چه با بسته‌بندی‌ها و چه با آینده‌ها.
- **پیچیدگی‌های اضافی**: استفاده از آینده‌ها ممکن است پیچیدگی‌هایی مانند نیاز به یک زمان‌اجرای ناهمزمان یا مدیریت چرخه‌های زندگی آینده را معرفی کند، اما می‌تواند مزایایی مانند مقیاس‌پذیری بهتر برای کارهای ورودی/خروجی-محور فراهم کند.

این پروژه یک پایه محکم برای کاوش بیشتر در برنامه‌نویسی ناهمزمان در Rust فراهم می‌کند، و شما می‌توانید با آزمایش زمان‌اجراهای ناهمزمان یا سایر الگوهای مدیریت وظیفه آن را گسترش دهید.