# مبانی برنامه‌نویسی غیرهمزمان: Async، Await، Futures و Streams

بسیاری از عملیاتی که از کامپیوتر می‌خواهیم انجام دهد، ممکن است زمان زیادی طول بکشد تا کامل شوند. خوب است اگر بتوانیم در حالی که منتظر تکمیل این فرآیندهای طولانی هستیم، کار دیگری انجام دهیم. کامپیوترهای مدرن دو تکنیک برای کار روی بیش از یک عملیات به طور همزمان ارائه می‌دهند: **موازی‌سازی** (parallelism) و **همزمانی** (concurrency). اما وقتی شروع به نوشتن برنامه‌هایی می‌کنیم که شامل عملیات موازی یا همزمان هستند، به سرعت با چالش‌های جدیدی مواجه می‌شویم که ذات برنامه‌نویسی غیرهمزمان هستند، جایی که عملیات ممکن است به ترتیب شروع‌شده‌شان به پایان نرسند. این فصل بر اساس استفاده از نخ‌ها برای موازی‌سازی و همزمانی در فصل شانزدهم، رویکرد جایگزینی برای برنامه‌نویسی غیرهمزمان معرفی می‌کند: **Futureها** (Futures)، **استریم‌ها** (Streams)، نحو `async` و `await` که از آن‌ها پشتیبانی می‌کند، و ابزارهایی برای مدیریت و هماهنگی بین عملیات‌های غیرهمزمان.

## مثال کاربردی

فرض کنید در حال صادر کردن (export) یک ویدیو از یک جشن خانوادگی هستید که خودتان ساخته‌اید، عملیاتی که ممکن است از چند دقیقه تا چند ساعت طول بکشد. صادرات ویدیو از حداکثر توان CPU و GPU استفاده خواهد کرد. اگر فقط یک هسته CPU داشتید و سیستم‌عامل شما صادرات را تا زمان تکمیل متوقف نمی‌کرد—یعنی اگر آن را به‌صورت **همزمان** (synchronously) اجرا می‌کرد—نمی‌توانستید در حین انجام این کار هیچ کار دیگری روی کامپیوترتان انجام دهید. این تجربه‌ای بسیار خسته‌کننده خواهد بود. خوشبختانه، سیستم‌عامل کامپیوتر شما می‌تواند، و این کار را انجام می‌دهد، به‌طور نامرئی صادرات را به اندازه کافی متوقف می‌کند تا به شما اجازه دهد کارهای دیگری را به طور همزمان انجام دهید.

حالا فرض کنید در حال دانلود یک ویدیو هستید که شخص دیگری به اشتراک گذاشته است، که این هم می‌تواند زمان‌بر باشد اما CPU زیادی مصرف نمی‌کند. در این مورد، CPU باید منتظر رسیدن داده‌ها از شبکه بماند. در حالی که می‌توانید خواندن داده‌ها را به محض شروع رسیدن آن‌ها آغاز کنید، ممکن است مدتی طول بکشد تا همه آن‌ها دریافت شوند. حتی وقتی همه داده‌ها حاضر باشند، اگر ویدیو بسیار بزرگ باشد، ممکن است حداقل یک یا دو ثانیه طول بکشد تا همه آن بارگذاری شود. این ممکن است زیاد به نظر نرسد، اما برای یک پردازنده مدرن که می‌تواند میلیاردها عملیات را در هر ثانیه انجام دهد، زمان بسیار طولانی است. باز هم، سیستم‌عامل شما برنامه‌تان را به‌طور نامرئی متوقف می‌کند تا به CPU اجازه دهد کارهای دیگری را در حین انتظار برای تکمیل فراخوانی شبکه انجام دهد.

صادرات ویدیو نمونه‌ای از یک عملیات **محدود شده توسط CPU** یا **محدود شده توسط محاسبات** (compute-bound) است. این عملیات توسط سرعت پردازش داده‌های بالقوه کامپیوتر در CPU یا GPU و میزان سرعتی که می‌تواند به این عملیات اختصاص دهد محدود می‌شود. دانلود ویدیو نمونه‌ای از یک عملیات **محدود شده توسط ورودی/خروجی** (IO-bound) است، زیرا توسط سرعت ورودی و خروجی کامپیوتر محدود می‌شود؛ فقط به همان سرعتی می‌تواند پیش برود که داده‌ها می‌توانند از طریق شبکه ارسال شوند.

در هر دو این مثال‌ها، توقف‌های نامرئی سیستم‌عامل نوعی همزمانی را فراهم می‌کند. با این حال، این همزمانی فقط در سطح کل برنامه اتفاق می‌افتد: سیستم‌عامل یک برنامه را متوقف می‌کند تا به برنامه‌های دیگر اجازه دهد کار کنند. در بسیاری از موارد، چون ما برنامه‌های خود را در سطح بسیار دقیق‌تری نسبت به سیستم‌عامل درک می‌کنیم، می‌توانیم فرصت‌های همزمانی را ببینیم که سیستم‌عامل نمی‌تواند آن‌ها را تشخیص دهد.

برای مثال، اگر در حال ساخت ابزاری برای مدیریت دانلود فایل‌ها هستیم، باید بتوانیم برنامه خود را طوری بنویسیم که شروع یک دانلود رابط کاربری (UI) را قفل نکند، و کاربران باید بتوانند چندین دانلود را به طور همزمان شروع کنند. با این حال، بسیاری از APIهای سیستم‌عامل برای تعامل با شبکه **مسدودکننده** (blocking) هستند؛ یعنی پیشرفت برنامه را تا زمانی که داده‌هایی که در حال پردازش آن‌ها هستند کاملاً آماده شوند، متوقف می‌کنند.

> **توجه**: اگر به این فکر کنید، این نحوه عملکرد اکثر فراخوانی‌های تابع است. با این حال، اصطلاح **مسدودکننده** معمولاً برای فراخوانی‌های تابعی که با فایل‌ها، شبکه، یا سایر منابع روی کامپیوتر تعامل دارند رزرو می‌شود، زیرا این‌ها مواردی هستند که یک برنامه خاص از غیرمسدودکننده بودن عملیات سود می‌برد.

می‌توانستیم با ایجاد یک نخ اختصاصی برای دانلود هر فایل، از مسدود کردن نخ اصلی جلوگیری کنیم. اما سربار این نخ‌ها در نهایت به مشکلی تبدیل می‌شود. ترجیحاً اگر فراخوانی از ابتدا مسدود نمی‌کرد، بهتر بود. همچنین بهتر بود اگر می‌توانستیم به همان سبک مستقیم که در کد مسدودکننده استفاده می‌کنیم، بنویسیم، مشابه این:

```rust
// این کد کامپایل نمی‌شود!
let data = fetch_data_from(url).await;
println!("{data}");
```

این دقیقاً همان چیزی است که abstraction **async** (مخفف asynchronous) در Rust به ما می‌دهد. در این فصل، همه چیز درباره async را خواهید آموخت، در حالی که موضوعات زیر را پوشش می‌دهیم:

- نحوه استفاده از نحو `async` و `await` در Rust
- نحوه استفاده از مدل async برای حل برخی از چالش‌هایی که در فصل شانزدهم بررسی کردیم
- چگونه چندنخی (multithreading) و async راه‌حل‌های مکملی ارائه می‌دهند که در بسیاری از موارد می‌توانید آن‌ها را ترکیب کنید

قبل از اینکه ببینیم async در عمل چگونه کار می‌کند، باید یک انحراف کوتاه داشته باشیم تا تفاوت بین موازی‌سازی و همزمانی را بحث کنیم.

## موازی‌سازی و همزمانی

تاکنون موازی‌سازی و همزمانی را تا حد زیادی به‌عنوان مفاهیم قابل‌تعویض در نظر گرفته‌ایم. حالا باید بین آن‌ها دقیق‌تر تمایز قائل شویم، زیرا این تفاوت‌ها با شروع کار ما آشکار خواهند شد.

روش‌های مختلفی را که یک تیم می‌تواند کار روی یک پروژه نرم‌افزاری را تقسیم کند، در نظر بگیرید. می‌توانید به یک عضو چندین وظیفه اختصاص دهید، به هر عضو یک وظیفه اختصاص دهید، یا ترکیبی از این دو رویکرد را استفاده کنید.

وقتی یک فرد روی چندین وظیفه مختلف کار می‌کند قبل از اینکه هیچ‌کدام از آن‌ها کامل شود، این **همزمانی** است. شاید شما دو پروژه مختلف روی کامپیوتر خود دارید، و وقتی از یکی خسته یا گیر می‌کنید، به دیگری سوئیچ می‌کنید. شما فقط یک نفر هستید، بنابراین نمی‌توانید دقیقاً در یک زمان روی هر دو وظیفه پیشرفت کنید، اما می‌توانید چندوظیفه‌ای (multi-task) انجام دهید، با جابه‌جایی بین آن‌ها به نوبت روی هر کدام پیشرفت کنید (شکل 17-1 را ببینید).

![شکل 17-1: یک جریان کاری همزمان، جابه‌جایی بین وظیفه A و وظیفه B](img/trpl17-01.svg)

وقتی تیم گروهی از وظایف را با اختصاص دادن یک وظیفه به هر عضو و کار کردن روی آن به تنهایی تقسیم می‌کند، این **موازی‌سازی** است. هر فرد در تیم می‌تواند دقیقاً در همان زمان پیشرفت کند (شکل 17-2 را ببینید).

![شکل 17-2: یک جریان کاری موازی، جایی که کار روی وظیفه A و وظیفه B به‌طور مستقل انجام می‌شود](img/trpl17-02.svg)

در هر دو این جریان‌های کاری، ممکن است لازم باشد بین وظایف مختلف هماهنگی کنید. شاید فکر می‌کردید وظیفه‌ای که به یک نفر اختصاص داده شده کاملاً مستقل از کار دیگران است، اما در واقع به تکمیل وظیفه شخص دیگری وابسته است. بخشی از کار می‌توانست به‌صورت موازی انجام شود، اما بخشی از آن در واقع **سریالی** (serial) بود: فقط می‌توانست به ترتیب، یکی پس از دیگری، اتفاق بیفتد، همان‌طور که در شکل 17-3 نشان داده شده است.

![شکل 17-3: یک جریان کاری نیمه‌موازی، جایی که کار روی وظیفه A و وظیفه B به‌طور مستقل انجام می‌شود تا زمانی که وظیفه A3 به نتایج وظیفه B3 وابسته شود.](img/trpl17-03.svg)

به همین ترتیب، ممکن است متوجه شوید که یکی از وظایف خودتان به وظیفه دیگری از وظایف شما وابسته است. حالا کار همزمان شما نیز سریالی شده است.

موازی‌سازی و همزمانی می‌توانند با یکدیگر تلاقی کنند. اگر بفهمید که یکی از همکاران تا زمانی که شما یکی از وظایف خود را تمام نکنید گیر کرده است، احتمالاً تمام تلاش خود را روی آن وظیفه متمرکز می‌کنید تا همکارتان را «رفع انسداد» کنید. شما و همکارتان دیگر نمی‌توانید به‌صورت موازی کار کنید، و همچنین دیگر نمی‌توانید به‌صورت همزمان روی وظایف خودتان کار کنید.

همین دینامیک‌های اساسی در نرم‌افزار و سخت‌افزار نیز نقش دارند. در ماشینی با یک هسته CPU، CPU فقط می‌تواند یک عملیات را در یک زمان انجام دهد، اما همچنان می‌تواند به‌صورت همزمان کار کند. با استفاده از ابزارهایی مانند نخ‌ها، پروسه‌ها و async، کامپیوتر می‌تواند یک فعالیت را متوقف کند و به فعالیت‌های دیگر سوئیچ کند قبل از اینکه دوباره به فعالیت اول بازگردد. در ماشینی با چندین هسته CPU، همچنین می‌تواند کار را به‌صورت موازی انجام دهد. یک هسته می‌تواند یک وظیفه را انجام دهد در حالی که هسته دیگر وظیفه‌ای کاملاً غیرمرتبط را انجام می‌دهد، و این عملیات‌ها واقعاً در همان زمان اتفاق می‌افتند.

وقتی با async در Rust کار می‌کنیم، همیشه با **همزمانی** سر و کار داریم. بسته به سخت‌افزار، سیستم‌عامل، و **زمان‌اجرای async** (async runtime) که استفاده می‌کنیم (در ادامه درباره زمان‌اجرای async بیشتر توضیح خواهیم داد)، این همزمانی ممکن است در پشت صحنه از موازی‌سازی نیز استفاده کند.

حالا بیایید به این بپردازیم که برنامه‌نویسی غیرهمزمان در Rust واقعاً چگونه کار می‌کند.