# کنار هم قرار دادن همه چیز: فیوچرها، وظایف، و نخ‌ها

همان‌طور که در فصل شانزدهم دیدیم، نخ‌ها (threads) یک رویکرد برای همزمانی ارائه می‌دهند. در این فصل، رویکرد دیگری را دیدیم: استفاده از `async` با فیوچرها و استریم‌ها. اگر فکر می‌کنید که چه زمانی باید یکی را به دیگری ترجیح داد، پاسخ این است: بستگی دارد! و در بسیاری از موارد، انتخاب بین نخ‌ها یا `async` نیست، بلکه نخ‌ها **و** `async` است.

بسیاری از سیستم‌عامل‌ها دهه‌هاست که مدل‌های همزمانی مبتنی بر نخ را ارائه می‌دهند، و به همین دلیل بسیاری از زبان‌های برنامه‌نویسی از آن‌ها پشتیبانی می‌کنند. با این حال، این مدل‌ها بدون معاوضه نیستند. در بسیاری از سیستم‌عامل‌ها، هر نخ مقدار قابل‌توجهی حافظه مصرف می‌کند و برای راه‌اندازی و خاموش کردن آن‌ها سرباری وجود دارد. نخ‌ها همچنین تنها زمانی گزینه هستند که سیستم‌عامل و سخت‌افزار شما از آن‌ها پشتیبانی کنند. برخلاف کامپیوترهای رومیزی و موبایل‌های主流، برخی سیستم‌های نهفته اصلاً سیستم‌عامل ندارند، بنابراین نخ هم ندارند.

مدل `async` مجموعه‌ای متفاوت—و در نهایت مکمل—از معاوضه‌ها را ارائه می‌دهد. در مدل `async`، عملیات‌های همزمان نیازی به نخ‌های خودشان ندارند. در عوض، می‌توانند روی وظایف (tasks) اجرا شوند، همان‌طور که وقتی از `trpl::spawn_task` برای شروع کار از یک تابع همزمان در بخش استریم‌ها استفاده کردیم. یک وظیفه مشابه یک نخ است، اما به جای مدیریت توسط سیستم‌عامل، توسط کد سطح کتابخانه مدیریت می‌شود: زمان‌اجرا (runtime).

در بخش قبلی، دیدیم که می‌توانیم یک استریم را با استفاده از یک کانال غیرهمزمان و ایجاد یک وظیفه غیرهمزمان که می‌توانستیم از کد همزمان فراخوانی کنیم، بسازیم. دقیقاً همین کار را می‌توانیم با یک نخ انجام دهیم. در Listing 17-40، از `trpl::spawn_task` و `trpl::sleep` استفاده کردیم. در Listing 17-41، این‌ها را با APIهای `thread::spawn` و `thread::sleep` از کتابخانه استاندارد در تابع `get_intervals` جایگزین می‌کنیم.

**فایل: src/main.rs**

```rust
use std::{thread, time::Duration};
use trpl::{ReceiverStream, Stream};

fn get_intervals() -> impl Stream<Item = u32> {
    let (tx, rx) = trpl::channel();

    // این *نه* `trpl::spawn` بلکه `std::thread::spawn` است!
    thread::spawn(move || {
        let mut count = 0;
        loop {
            // به همین ترتیب، این *نه* `trpl::sleep` بلکه `std::thread::sleep` است!
            thread::sleep(Duration::from_millis(1));
            count += 1;

            if let Err(send_error) = tx.send(count) {
                eprintln!("نمی‌توان بازه {count} را ارسال کرد: {send_error}"); // Could not send interval {count}: {send_error}
                break;
            };
        }
    });

    ReceiverStream::new(rx)
}
```

**Listing 17-41: استفاده از APIهای std::thread به جای APIهای غیرهمزمان trpl برای تابع get_intervals**

اگر این کد را اجرا کنید، خروجی آن مشابه خروجی Listing 17-40 است. و توجه کنید که از دیدگاه کد فراخواننده چقدر تغییر کمی ایجاد می‌شود. علاوه بر این، حتی با اینکه یکی از توابع ما یک وظیفه غیرهمزمان روی زمان‌اجرا ایجاد کرد و دیگری یک نخ سیستم‌عامل ایجاد کرد، استریم‌های حاصل از این تفاوت‌ها تحت تأثیر قرار نگرفتند.

با وجود شباهت‌هایشان، این دو رویکرد بسیار متفاوت عمل می‌کنند، اگرچه ممکن است در این مثال بسیار ساده سنجش آن دشوار باشد. ما می‌توانستیم میلیون‌ها وظیفه غیرهمزمان را روی هر کامپیوتر شخصی مدرن ایجاد کنیم. اگر سعی کنیم این کار را با نخ‌ها انجام دهیم، به معنای واقعی کلمه حافظه تمام می‌شود!

با این حال، دلیلی وجود دارد که این APIها اینقدر شبیه هستند. نخ‌ها به‌عنوان مرزی برای مجموعه‌های عملیات همزمان عمل می‌کنند؛ همزمانی بین نخ‌ها ممکن است. وظایف به‌عنوان مرزی برای مجموعه‌های عملیات غیرهمزمان عمل می‌کنند؛ همزمانی هم بین وظایف و هم درون وظایف ممکن است، زیرا یک وظیفه می‌تواند بین فیوچرها در بدنه خود جابه‌جا شود. در نهایت، فیوچرها کوچک‌ترین واحد همزمانی در Rust هستند، و هر فیوچر ممکن است درختی از فیوچرهای دیگر را نشان دهد. زمان‌اجرا—به‌ویژه اجراکننده (executor) آن—وظایف را مدیریت می‌کند، و وظایف فیوچرها را مدیریت می‌کنند. در این زمینه، وظایف شبیه نخ‌های سبک‌وزن مدیریت‌شده توسط زمان‌اجرا هستند با قابلیت‌های اضافی که از مدیریت توسط زمان‌اجرا به جای سیستم‌عامل ناشی می‌شود.

این به این معنا نیست که وظایف غیرهمزمان همیشه بهتر از نخ‌ها هستند (یا برعکس). همزمانی با نخ‌ها در برخی جهات مدل برنامه‌نویسی ساده‌تری نسبت به همزمانی با `async` است. این می‌تواند یک نقطه قوت یا ضعف باشد. نخ‌ها تا حدی «شلیک کن و فراموش کن» هستند؛ آن‌ها معادل ذاتی یک فیوچر ندارند، بنابراین به‌سادگی تا تکمیل شدن اجرا می‌شوند بدون اینکه جز توسط خود سیستم‌عامل قطع شوند. یعنی، آن‌ها هیچ پشتیبانی داخلی برای همزمانی درون‌وظیفه‌ای به روشی که فیوچرها دارند، ندارند. نخ‌ها در Rust همچنین هیچ مکانیزمی برای لغو ندارند—موضوعی که در این فصل به‌طور صریح پوشش ندادیم اما به‌طور ضمنی با این واقعیت که هر زمان یک فیوچر را پایان دادیم، حالت آن به‌درستی پاکسازی شد، اشاره شد.

این محدودیت‌ها همچنین ترکیب نخ‌ها را دشوارتر از فیوچرها می‌کند. برای مثال، استفاده از نخ‌ها برای ساخت دستیارهایی مانند متدهای `timeout` و `throttle` که قبلاً در این فصل ساختیم، بسیار دشوارتر است. این واقعیت که فیوچرها ساختارهای داده غنی‌تری هستند به این معناست که می‌توانند به‌طور طبیعی‌تر با هم ترکیب شوند، همان‌طور که دیدیم.

وظایف، در نتیجه، کنترل بیشتری روی فیوچرها به ما می‌دهند، و به ما اجازه می‌دهند انتخاب کنیم که کجا و چگونه آن‌ها را گروه‌بندی کنیم. و مشخص می‌شود که نخ‌ها و وظایف اغلب خیلی خوب با هم کار می‌کنند، زیرا وظایف می‌توانند (حداقل در برخی زمان‌اجراها) بین نخ‌ها جابه‌جا شوند. در واقع، در پشت صحنه، زمان‌اجرایی که ما استفاده کردیم—از جمله توابع `spawn_blocking` و `spawn_task`—به‌طور پیش‌فرض چندنخی است! بسیاری از زمان‌اجراها از رویکردی به نام **دزدی کار** (work stealing) استفاده می‌کنند تا وظایف را به‌طور شفاف بین نخ‌ها جابه‌جا کنند، بر اساس اینکه نخ‌ها در حال حاضر چگونه استفاده می‌شوند، تا عملکرد کلی سیستم را بهبود دهند. این رویکرد در واقع به نخ‌ها و وظایف، و بنابراین فیوچرها، نیاز دارد.

وقتی فکر می‌کنید که از کدام روش چه زمانی استفاده کنید، این قوانین سرانگشتی را در نظر بگیرید:

- اگر کار بسیار موازی‌پذیر باشد، مانند پردازش مجموعه‌ای از داده‌ها که هر بخش می‌تواند به‌صورت جداگانه پردازش شود، نخ‌ها انتخاب بهتری هستند.
- اگر کار بسیار همزمان باشد، مانند مدیریت پیام‌ها از منابع مختلف که ممکن است در فواصل یا نرخ‌های مختلف وارد شوند، `async` انتخاب بهتری است.
- و اگر به هر دو موازی‌سازی و همزمانی نیاز دارید، نیازی به انتخاب بین نخ‌ها و `async` ندارید. می‌توانید آزادانه از آن‌ها با هم استفاده کنید، و اجازه دهید هر کدام نقشی را که در آن بهترین است ایفا کنند.

برای مثال، Listing 17-42 یک نمونه نسبتاً رایج از این نوع ترکیب در کد واقعی Rust را نشان می‌دهد.

**فایل: src/main.rs**

```rust
use std::{thread, time::Duration};
use trpl::StreamExt;

fn main() {
    let (tx, mut rx) = trpl::channel();

    thread::spawn(move || {
        for i in 1..11 {
            tx.send(i).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    trpl::run(async {
        while let Some(message) = rx.recv().await {
            println!("{message}");
        }
    });
}
```

**Listing 17-42: ارسال پیام‌ها با کد مسدودکننده در یک نخ و انتظار پیام‌ها در یک بلوک غیرهمزمان**

ما با ایجاد یک کانال غیرهمزمان شروع می‌کنیم، سپس یک نخ ایجاد می‌کنیم که مالکیت سمت فرستنده کانال را می‌گیرد. درون نخ، اعداد 1 تا 10 را ارسال می‌کنیم، بین هر کدام یک ثانیه می‌خوابیم. در نهایت، یک فیوچر ایجادشده با یک بلوک `async` را که به `trpl::run` پاس داده شده، همان‌طور که در طول فصل انجام دادیم، اجرا می‌کنیم. در آن فیوچر، آن پیام‌ها را انتظار می‌کنیم، درست مثل سایر نمونه‌های پیام‌رسانی که دیدیم.

برای بازگشت به سناریویی که در ابتدای فصل مطرح کردیم، تصور کنید مجموعه‌ای از وظایف رمزگذاری ویدئو را با استفاده از یک نخ اختصاصی اجرا می‌کنید (زیرا رمزگذاری ویدئو محاسباتی است) اما رابط کاربری را با یک کانال غیرهمزمان از اتمام آن عملیات‌ها مطلع می‌کنید. نمونه‌های بی‌شماری از این نوع ترکیب‌ها در موارد استفاده واقعی وجود دارد.

## خلاصه

این آخرین باری نیست که در این کتاب همزمانی را خواهید دید. پروژه در فصل بیست و یکم این مفاهیم را در موقعیت واقعی‌تری نسبت به نمونه‌های ساده‌تر بحث‌شده اینجا اعمال خواهد کرد و حل مسئله با نخ‌ها در مقابل وظایف را به‌طور مستقیم‌تر مقایسه خواهد کرد.

صرف‌نظر از اینکه کدام‌یک از این رویکردها را انتخاب کنید، Rust ابزارهایی را که برای نوشتن کد همزمان ایمن و سریع نیاز دارید—چه برای یک سرور وب با توان بالا یا یک سیستم‌عامل نهفته—در اختیارتان قرار می‌دهد.

در ادامه، درباره روش‌های اصولی مدل‌سازی مسائل و ساختاردهی راه‌حل‌ها صحبت خواهیم کرد وقتی برنامه‌های Rust شما بزرگ‌تر می‌شوند. علاوه بر این، بحث خواهیم کرد که چگونه اصول Rust به آن‌هایی که ممکن است از برنامه‌نویسی شیءگرا با آن‌ها آشنا باشید مرتبط می‌شوند.